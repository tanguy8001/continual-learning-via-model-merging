# -*- coding: utf-8 -*-
"""plane.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j68RBQMzwKmqm3b2a4FUrRkSQl3O0Zw2
"""


import torch
import numpy as np
import torch.nn.functional as F
import tqdm
import tabulate
import os
import argparse
import logging

from torch.utils import data
from torchvision import datasets, transforms

from src.tlp_model_fusion.utils import average_meter
from src.tlp_model_fusion import train_models
from src.tlp_model_fusion import datasets as mydatasets
from src.tlp_model_fusion import fuse_models
from src.tlp_model_fusion import model
from src.tlp_model_fusion import resnet_models
from src.tlp_model_fusion import tlp_fusion
from src.tlp_model_fusion import vgg_models
from src.tlp_model_fusion import init
from fuse_models import get_model
from src.tlp_rnn_fusion import fuse_rnn_models
from src.tlp_rnn_fusion import train_rnn_mnist
from init import make_dirs

### Load neural networks
def load_model(model_name, model_path):
  state_dict = torch.load(model_path)
  if model_name in ['RNN', 'LSTM', 'rnn', 'lstm']:
      model = fuse_rnn_models.get_model(model_name, input_dim=28, config=state_dict['config'], encoder=False)
  else:
      model = fuse_models.get_model(model_name, state_dict['config'])
  model.load_state_dict(state_dict['model_state_dict'])
  return model 

### Get coordinate
def get_xy(point, origin, vector_x, vector_y):
  return np.array([np.dot(point - origin, vector_x), np.dot(point - origin, vector_y)])

##### Test function
def test(dataloader, model, model_name='FC'):
  #tbar = tqdm.tqdm(dataloader)
  total = 0
  correct = 0
  loss_logger = average_meter.AverageMeter()
  
  if torch.cuda.is_available():
    model = model.cuda()
  
  model.eval()

  for batch_idx, (images, labels) in enumerate(dataloader):
    if torch.cuda.is_available():
      images = images.cuda()
      labels = labels.cuda()
    if model_name == 'FC':
      logits = model(images.view(images.size(0), -1))
    elif model_name in ['ImageRNN', 'ImageLSTM', 'RNN']:
      logits = model(images.squeeze())
    else:
      logits = model(images)
    
    loss = F.cross_entropy(logits, labels)
    prediction = torch.argmax(logits, dim=1)
    total += images.size(0)
    correct += torch.sum(labels == prediction)
    loss_logger.update(loss.item())

  accuracy = 100.0 * correct / total
  return {
      'loss': loss_logger.avg,
      'accuracy': accuracy,
  }

def loss_func(last_output, y):
  m = torch.nn.LogSoftmax(dim=1)
  loss = torch.nn.NLLLoss(reduction='mean')

  return (loss(m(last_output), y))


def test_rnn(dataloader, model, dataset_name='MNISTNorm'):
  total = 0
  correct = 0
  loss = 0

  #loss_logger = average_meter.AverageMeter()
  
  if torch.cuda.is_available():
    model = model.cuda()
  
  model.eval()

  for batch_idx, samples_batched in enumerate(dataloader): # samples_batched - word sentences in a batch of sentences (batch_size, 100)
      x_batched, y_batched = samples_batched  # x_batched (bz, 80), y_batched (bz, 80, 1)
      if dataset_name in ['MNISTNorm', 'SplitMNIST', 'MNIST']:
          x_batched = torch.squeeze(x_batched)
      if torch.cuda.is_available():
          x_batched = x_batched.cuda()
          y_batched = y_batched.cuda()
      
      batch_size = x_batched.size(0)

      logits = model(x_batched)
      last_logits = logits[:, -1, :] # size(batch_size, vocab_size)

      batch_loss = loss_func(last_logits, y_batched)
      loss += batch_loss
      total += batch_size

      prediction = torch.argmax(last_logits.detach(), dim=1) # size(batch_size)
      correct += torch.sum(y_batched == prediction)
  
  avg_loss = loss / total
  accuracy = 100.0 * correct / total
  return {
      'loss': avg_loss,
      'accuracy': accuracy,
  }

    


### Get all the weight in one nerual network
def get_weight(model):
  weights = np.concatenate([p.cpu().detach().numpy().ravel() for p in model.parameters()])
  return weights

def main():
  parser = argparse.ArgumentParser()
  parser.add_argument('--experiment_name', type=str, default='test')
  parser.add_argument('--model_name', type=str, default='FC')
  parser.add_argument('--dataset_name', type=str, default='MNIST')
  parser.add_argument('--result_path', type=str, default='result')

  parser.add_argument('--data_path', type=str, default='./data')
  parser.add_argument('--batch_size', type=int, default=64)

  parser.add_argument('--normalize', default=False, action='store_true')
  parser.add_argument('--nsplits', type=int, default=1,
                        help='Number of splits of the dataset')
  parser.add_argument('--split_index', type=int, default=1,
                        help='The current index of split dataset used!')
  parser.add_argument('--ds_scale_factor', type=float, default=1.0,
                        help='To understand effect of ds scaling')
  parser.add_argument('--alpha_h', type=float, default=None, nargs='+',
                      help='The weight for the hidden to hidden matrix costs')

  parser.add_argument('--grid_points', type=int, default=21,
                      help='number of points in the grid (default: 21)')
  parser.add_argument('--margin_left', type=float, default=0.2,
                      help='left margin (default: 0.2)')
  parser.add_argument('--margin_right', type=float, default=0.2,
                      help='right margin (default: 0.2)')
  parser.add_argument('--margin_bottom', type=float, default=0.2,
                      help='bottom margin (default: 0.)')
  parser.add_argument('--margin_top', type=float, default=0.2,
                      help='top margin (default: 0.2)')

  parser.add_argument('--input_dim', type=int, default=784)
  parser.add_argument('--hidden_dims', type=int, nargs='+', default=[])
  parser.add_argument('--output_dim', type=int, default=10)

  parser.add_argument('--evaluate', default=False, action='store_true')
  parser.add_argument('--resume', default=False, action='store_true')
  parser.add_argument('--init_start', type=str, default=None,
                      help='checkpoint to init start point (default: None)')
  parser.add_argument('--init_end', type=str, default=None,
                      help='checkpoint to init end point (default: None)')
  parser.add_argument('--fused_model_path', type=str, default=None,
                      help='checkpoint to the fused model')
  parser.add_argument('--permuted_model_path', type=str, default=None)

  parser.add_argument('--no_cuda', default=False, action='store_true')
  parser.add_argument('--gpu_ids', type=str, default='0')
  parser.add_argument("--seed", default=24601, type=int)

  parser.add_argument('--hetero_special_digit', type=int, default=4,
                        help='Special digit for heterogeneous MNIST')
  parser.add_argument('--hetero_special_train', default=False, action='store_true',
                        help='If HeteroMNIST with special digit split is used for training.')
  parser.add_argument('--hetero_other_digits_train_split', default=0.9, type=float)
  parser.add_argument('--heterogeneous', default=False, action='store_true')

  parser.add_argument('--finetune_visualization', default=False, action='store_true')
  parser.add_argument('--finetuned_model_path', type=str, default=None,
                      help='checkpoint to the finetuned model') 
  

  logging.basicConfig(level=logging.INFO)
  logger = logging.getLogger(__name__)
  
  args = parser.parse_args()

  if args.heterogeneous:
    model_name = args.experiment_name + '_' + args.model_name + '_' + 'HeteroMNIST'
  else:
    model_name = args.experiment_name + '_' + args.model_name + '_' + args.dataset_name 
  output_path = os.path.join(args.result_path, model_name)
  make_dirs(output_path)
  name = model_name
  logging.info("Generating grid plane for %s", name)


  os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu_ids
  args.gpu_id_list = [int(s) for s in args.gpu_ids.split(',')]
  args.cuda = not args.no_cuda and torch.cuda.is_available()
  logging.basicConfig(level=logging.INFO)

  if args.finetune_visualization:
    model1 = load_model(args.model_name, args.init_start)
    model2 = load_model(args.model_name, args.init_end)
    fused_model = load_model(args.model_name, args.fused_model_path)
    finetuned_model = load_model(args.model_name, args.finetuned_model_path)

    #w = [get_weight(model1), get_weight(finetuned_model), get_weight(fused_model)]
    w = [get_weight(model1), get_weight(finetuned_model), get_weight(model2)]
    logging.info("Weight space dimentionality: {}".format(w[0].shape[0]))
  else:
    model1 = load_model(args.model_name, args.init_start)
    model2 = load_model(args.model_name, args.init_end)
    fused_model = load_model(args.model_name, args.fused_model_path)
    permuted_model_2 = load_model(args.model_name, args.permuted_model_path)

    ### Generate permuted model 2
    if args.model_name in ['ImageRNN', 'RNN', 'rnn', 'LSTM', 'lstm']:
      weights = []
      for fused_model_parameter, model1_parameter in zip(fused_model.parameters(), model1.parameters()):
        weight = 2 * fused_model_parameter - model1_parameter
        weights.append(weight)

    else:
      weights = []
      for i in range(1, fused_model.num_layers + 1):
        weight = 2 * fused_model.get_layer_weights(i) - model1.get_layer_weights(i)
        weights.append(weight)

    config = fused_model.get_model_config()
    if args.model_name in ['RNN', 'LSTM', 'rnn', 'lstm']:
        permuted_model2 = fuse_rnn_models.get_model(args.model_name, input_dim=28, config=config, encoder=False)
    else:
        permuted_model2 = get_model(args.model_name, config)
    for i, parameter in zip(range(len(weights)), permuted_model2.parameters()):
      parameter.data.copy_(weights[i])
    logging.info("Finish generating permuted model 2")

    ### Check whether two permuted models that are generated from two different ways are the same or not
    for parameter_1, parameter_2 in zip(permuted_model_2.parameters(), permuted_model2.parameters()):
        print((parameter_1 - parameter_2).pow(2).sum(-1).sum(-1))


    w = [get_weight(model1), get_weight(permuted_model_2), get_weight(model2)]
    fused_model_w = get_weight(fused_model)
    #w = [get_weight(model1), get_weight(fused_model), get_weight(model2)]
    logging.info("Weight space dimentionality: {}".format(w[0].shape[0]))

  
  config = model1.get_model_config()

  ### Generate orthonormal basises
  u = w[2] - w[0]
  dx = np.linalg.norm(u)
  u /= dx

  v = w[1] - w[0]
  v -= np.dot(u, v) * u
  dy = np.linalg.norm(v)
  v /= dy

  bend_coordinates = np.stack([get_xy(p, w[0], u, v) for p in w])
  logging.info('The coordinates of model 1 on the plane: {}'.format(bend_coordinates[0]))
  logging.info('The coordinates of model 2 on the plane {}'.format(bend_coordinates[2]))
  logging.info('The coordinates of permuted model 2 on the plane {}'.format(bend_coordinates[1]))

  fused_model_coordinates = get_xy(fused_model_w, w[0], u, v)
  logging.info('The coordinates of the fused model on the plane: {}'.format(fused_model_coordinates))

  ### Generate the grid plane
  trainloader, valoader, testloader = train_rnn_mnist.get_dataloaders(args)
  
  # Test whether the function test_rnn
  logging.info('Test accuracy of model 1:{}'.format(test_rnn(testloader, model1, args.dataset_name)))
  logging.info('Test accuracy of model 2:{}'.format(test_rnn(testloader, model2, args.dataset_name)))
  logging.info('Test accuracy of fused model:{}'.format(test_rnn(testloader, fused_model, args.dataset_name)))
  logging.info('Test accuracy of permuted model 2:{}'.format(test_rnn(testloader, permuted_model2, args.dataset_name)))

  G = args.grid_points
  alphas = np.linspace(0.0 - args.margin_left, 1.0 + args.margin_right, G)
  betas = np.linspace(0.0 - args.margin_bottom, 1.0 + args.margin_top, G)

  tr_loss = np.zeros((G, G))
  tr_acc = np.zeros((G, G))
  tr_err = np.zeros((G, G))

  te_loss = np.zeros((G, G))
  te_acc = np.zeros((G, G))
  te_err = np.zeros((G, G))

  grid = np.zeros((G, G, 2))
  
  if args.model_name in ['RNN', 'LSTM', 'rnn', 'lstm']:
      base_model = fuse_rnn_models.get_model(args.model_name, input_dim=28, config=config, encoder=False)
  else:
      base_model = get_model(args.model_name, config)
  if torch.cuda.is_available():
    base_model.cuda()

  columns = ['X', 'Y', 'Train loss', 'Train error (%)', 'Test error (%)']
  logging.info("Begin to generate grid plane.")

  for i, alpha in enumerate(alphas):
    for j, beta in enumerate(betas):
      # Generate the weights of the neural networks at point (i, j)
      p = w[0] + alpha * dx * u + beta * dy * v

      offset = 0
      for parameter in base_model.parameters():
        size = np.prod(parameter.size())
        value = p[offset:offset+size].reshape(parameter.size())
        parameter.data.copy_(torch.from_numpy(value))
        offset += size

      if args.model_name in ['RNN', 'LSTM', 'rnn', 'lstm']:
          tr_res = test_rnn(trainloader, base_model, args.dataset_name)
          te_res = test_rnn(testloader, base_model, args.dataset_name)
      else:
          tr_res = test(trainloader, base_model, args.model_name)
          te_res = test(testloader, base_model, args.model_name)

      tr_loss_v, tr_acc_v = tr_res['loss'], tr_res['accuracy']
      te_loss_v, te_acc_v = te_res['loss'], te_res['accuracy']

      c = get_xy(p, w[0], u, v)
      grid[i, j] = [alpha * dx, beta * dy]

      tr_loss[i, j] = tr_loss_v
      tr_acc[i, j] = tr_acc_v
      tr_err[i, j] = 100.0 - tr_acc[i, j]

      te_loss[i, j] = te_loss_v
      te_acc[i, j] = te_acc_v
      te_err[i, j] = 100.0 - te_acc[i, j]

      values = [
              grid[i, j, 0], grid[i, j, 1], tr_loss[i, j], tr_err[i, j], te_err[i, j]
      ]

      table = tabulate.tabulate([values], columns, tablefmt = 'simple', floatfmt='10.4f')
      if j == 0:
        table = table.split('\n')
        table = '\n'.join([table[1]] + table)
      else:
        table = table.split('\n')[2]
      print(table)
  
  np.savez(
      os.path.join(output_path, 'plane.npz'),
      bend_coordinates = bend_coordinates,
      fused_model_coordinates = fused_model_coordinates,
      alphas = alphas,
      betas = betas,
      grid = grid,
      tr_loss = tr_loss,
      tr_acc = tr_acc,
      tr_err = tr_err,
      te_loss = te_loss,
      te_acc = te_acc,
      te_err = te_err
  )

if __name__ == "__main__":
  main()